{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2A: Launch Local Training Job\n",
    "\n",
    "In this notebook, we will generate the training command to train our reinforcement learning model on a single machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the following hyperparameters for the training job:\n",
    "\n",
    "* **batch_update_frequency**: This is how often the weights from the actively trained network get copied to the target network. It is also how often the model gets saved to disk. For more details on how this works, check out the [Deep Q-learning paper](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf).\n",
    "* **max_epoch_runtime_sec**: This is the maximum runtime for each epoch. If the car has not reached a terminal state after this many seconds, the epoch will be terminated and training will begin.\n",
    "* **per_iter_epsilon_reduction**: The agent uses an epsilon greedy linear annealing strategy while training. This is the amount by which epsilon is reduced each iteration.\n",
    "* **min_epsilon**: The minimum value for epsilon. Once reached, the epsilon value will not decrease any further.\n",
    "* **batch_size**: The minibatch size to use for training.\n",
    "* **replay_memory_size**: The number of examples to keep in the replay memory. The replay memory is a FIFO buffer used to reduce the effects of nearby states being correlated. Minibatches are generated from randomly selecting examples from the replay memory.\n",
    "* **weights_path**: If we are doing transfer learning and using pretrained weights for the model, they will be loaded from this path.\n",
    "* **train_conv_layers**: If we are using pretrained weights, we may prefer to freeze the convolutional layers to speed up training.\n",
    "* **airsim_path**: The path to the folder containing the .ps1 to start AirSim. This path cannot contain spaces.\n",
    "* **data_dir**: The path to the directory containing the road_points.txt and reward_points.txt used to compute the reward function. This path cannot contain spaces.\n",
    "* **experiment_name**: A unique identifier for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_update_frequency = 300\n",
    "#batch_update_frequency = 10\n",
    "max_epoch_runtime_sec = 30\n",
    "per_iter_epsilon_reduction=0.003\n",
    "min_epsilon = 0.1\n",
    "batch_size = 32\n",
    "#replay_memory_size = 2000\n",
    "replay_memory_size = 50\n",
    "weights_path = os.path.join(os.getcwd(), 'Share\\\\data\\\\pretrain_model_weights.h5')\n",
    "train_conv_layers = 'false'\n",
    "airsim_path = 'C:\\\\Airsim\\\\AD_Cookbook_AirSim'\n",
    "data_dir = os.path.join(os.getcwd(), 'Share')\n",
    "experiment_name = 'local_run'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate a training batch file. The file will be written to *Share\\scripts_downpour\\app*. Run this file from an activated python environment in that directory to kick off the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cmd = 'python distributed_agent.py'\n",
    "train_cmd += ' batch_update_frequency={0}'.format(batch_update_frequency)\n",
    "train_cmd += ' max_epoch_runtime_sec={0}'.format(max_epoch_runtime_sec)\n",
    "train_cmd += ' per_iter_epsilon_reduction={0}'.format(per_iter_epsilon_reduction)\n",
    "train_cmd += ' min_epsilon={0}'.format(min_epsilon)\n",
    "train_cmd += ' batch_size={0}'.format(batch_size)\n",
    "train_cmd += ' replay_memory_size={0}'.format(replay_memory_size)\n",
    "train_cmd += ' weights_path={0}'.format(weights_path)\n",
    "train_cmd += ' train_conv_layers={0}'.format(train_conv_layers)\n",
    "train_cmd += ' airsim_path={0}'.format(airsim_path)\n",
    "train_cmd += ' data_dir={0}'.format(data_dir)\n",
    "train_cmd += ' experiment_name={0}'.format(experiment_name)\n",
    "train_cmd += ' local_run=true'\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'Share/scripts_downpour/app/train.bat'), 'w') as f:\n",
    "    f.write(train_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that training the model from scratch can take up to 5 days on a powerful GPU. Using pre-trained weights, the model should begin to visibly converge after 3 hours of training. Once the model has trained, move on to **[Step 3 - Run the Model](RunModel.ipynb)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
